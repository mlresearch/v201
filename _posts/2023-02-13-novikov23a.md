---
title: Dictionary Learning for the Almost-Linear Sparsity Regime
abstract: "\\textit{Dictionary learning}, the problem of recovering a sparsely used
  matrix $\\mathbf{D} \\in \\mathbb{R}^{M \\times K}$ and $N$ independent $K \\times
  1$ $s$-sparse vectors $\\mathbf{X} \\in \\mathbb{R}^{K \\times N}$ from samples
  of the form $\\mathbf{y} = \\mathbf{D}\\mathbf{X}$, is of increasing importance
  to applications in signal processing and data science. Early papers on provable
  dictionary learning identified that one can detect whether two samples $\\mathbf{y}_i,
  \\mathbf{y}_j$ share a common dictionary element by testing if their inner product
  (correlation) exceeds a certain threshold: $|{\\left⟨\\mathbf{y}_i, \\mathbf{y}_j
  \\right⟩}| > \\tau$. These correlation-based methods work well when sparsity is
  small, but suffer from declining performance when sparsity grows faster than $\\sqrt{M}$;
  as a result, such methods were abandoned in the search for dictionary learning algorithms
  when sparsity is nearly linear in $M$. In this paper, we revisit correlation-based
  dictionary learning. Instead of seeking to recover individual dictionary atoms,
  we employ a spectral method to recover the subspace spanned by the dictionary atoms
  in the support of each sample. This approach circumvents the primary challenge encountered
  by previous correlation methods, namely that when sharing information between two
  samples it is difficult to tell \\textit{which} dictionary element the two samples
  share. We prove that under a suitable random model the resulting algorithm recovers
  dictionaries in polynomial time for sparsity linear in $M$ up to log factors. Our
  results improve on the best known methods by achieving a decaying error bound in
  dimension $M$; the best previously known results for the overcomplete ($K > M$)
  setting achieve polynomial time in the linear regime only for constant error bounds.
  Numerical simulations confirm our results."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: novikov23a
month: 0
tex_title: Dictionary Learning for the Almost-Linear Sparsity Regime
firstpage: 1516
lastpage: 1554
page: 1516-1554
order: 1516
cycles: false
bibtex_author: Novikov, Alexei and White, Stephen
author:
- given: Alexei
  family: Novikov
- given: Stephen
  family: White
date: 2023-02-13
address:
container-title: Proceedings of The 34th International Conference on Algorithmic Learning
  Theory
volume: '201'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 2
  - 13
pdf: https://proceedings.mlr.press/v201/novikov23a/novikov23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
