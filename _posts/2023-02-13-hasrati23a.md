---
title: On Computable Online Learning
abstract: We initiate the first study of computable online (c-online) learning, which
  we analyse under varying requirements for “optimality” in terms of the mistake bound.
  Our main contribution is to give a necessary and sufficient condition for optimal
  c-online learning and show that the Littlestone dimension no longer characterizes
  the optimal mistake bound of c-online learning. Furthermore, we introduce anytime
  optimal (a-optimal) online learning, a more natural conceptualization of “optimality”
  and a generalization of Littlestone’s Standard Optimal Algorithm. We show the existence
  of a computational separation between a-optimal and optimal online learning, proving
  that a-optimal online learning is computationally more difficult. Finally, we consider
  online learning with no requirements for optimality, and show, under a weaker notion
  of computability, that the finiteness of the Littlestone dimension no longer characterizes
  whether a class is c-online learnable with finite mistake bound. A potential avenue
  for strengthening this result is suggested by exploring the relationship between
  c-online and CPAC learning, where we show that c-online learning is as difficult
  as improper CPAC learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hasrati23a
month: 0
tex_title: On Computable Online Learning
firstpage: 707
lastpage: 725
page: 707-725
order: 707
cycles: false
bibtex_author: Hasrati, Niki and Ben-David, Shai
author:
- given: Niki
  family: Hasrati
- given: Shai
  family: Ben-David
date: 2023-02-13
address:
container-title: Proceedings of The 34th International Conference on Algorithmic Learning
  Theory
volume: '201'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 2
  - 13
pdf: https://proceedings.mlr.press/v201/hasrati23a/hasrati23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
